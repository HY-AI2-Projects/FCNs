# FCNs
FCN is a model that emerged in the field of computer vision in 2015, a time when there were not many artificial intelligence models. While there were classification models like VGGnet and GoogLeNet, and an object detection model called the R-CNN model, there was no specific solution for segmentation problems in computer vision tasks at that time. Although traditional CNN models could be used for segmentation, they were primarily classification-based models. This meant they analyzed the entire image by finding and abstracting global features. Object detection models were not widely applicable as they required dedicated pattern recognition filters. This text aims to explain the FCN model, which allows predictions for each pixel. It's worth noting that conventional segmentation methods used patchwise and pixelwise approaches, but these methods were computationally expensive and involved significant pre and post-processing due to issues like superpixels.

Let's define three key features of the FCN model:

Firstly, the significance of the FCN model lies in being a preprocessing-free image segmentation model. Traditional CNN models go through convolutional layers, pooling layers, and end with a fully connected layer. In contrast, FCN does not have a fully connected layer. Typical CNN models extract local features of the image through convolutional and pooling layers and abstract this process to find class information in the output layer through a fully connected layer. For example, the VGG16 model has an output layer composed of 1000 nodes for classifying 1000 classes. However, the problem with this structure is that the weights of the fully connected layer are fixed, causing the size of the feature map from the preceding layer and consequently the input image size to be fixed. FCN replaces this fully connected layer with a convolutional layer, a technique known as convolutionalization. As a result, there are no structural constraints on the output layer, eliminating the limitation on input size. FCN is a technology in the segmentation field, requiring both the classification ability of CNN and localization information about the object's position. Conventional CNN models, focusing on extracting local features, lose information about the position since the process abstracts away the detailed spatial information of the entire image. This problem arises in the fully connected layer where all pixels are connected in a line. FCN addresses this by removing the fully connected layer, applying convolutionalization, and representing the information for each pixel in heatmap format. The convolutionalization method involves applying multiple 1x1 filters to maintain the number of weights according to the number of nodes in the original fully connected layer. In the case of VGG16, which has 4096 nodes in the fully connected layer, this method applies 4096 1x1 filters.

To summarize, the significance of FCN lies in performing image segmentation without preprocessing by utilizing convolutionalization. Secondly, FCN employs specific techniques for image segmentation. As seen in the previous content, compressed heatmaps are extracted by convolutionalization to predict pixel-wise segmentation. However, a special technique is needed for the final pixel-wise prediction from the compressed image. This technique involves using an inverse filtering method to enlarge the compressed image. FCN utilizes shift and stitch, bilinear interpolation, and the deconvolution method. The deconvolution method restores the size of the image by using the reverse operation of convolution, allowing pixel-wise prediction. Thirdly, the structure of FCN can be viewed as an encoder-decoder structure. In the encoder structure, the same process of compressing/abstracting images for classification is performed, and the feature map is compressed 1/32 times through 5 convolutional-pooling layers. The encoder obtains meaningful information about the entire image, which is global information, depending on the goal of CNN. The decoder then enhances the compressed feature map.

The most basic FCN-32 method involves 32x enlargement through deconvolution, but the image quality deteriorates. To address this, the FCN-16 model was introduced. This model enlarges by 2 times, then combines 4 times the feature map of the pooling layer 4, and again enlarges 16 times. It brings in parts of the original feature map to improve the image quality. The FCN-8 model, applying the same method, enlarges by 2 times, combines 4 times the feature map of pooling layer 4, enlarges by 2 times, combines 3 times the feature map of pooling layer 3, and then enlarges 8 times. As a result, the decoder can obtain detailed image information from the shallow layer before encoding, and when looking at the performance metrics in related papers, the pixel accuracy between the actual image and the predicted image increases. In summary, the structure of FCN can be summarized as a model that restores information that could have been lost during encoding through skip architecture, combining information from the previous feature map, and mixing the entire image information obtained through encoding with the detailed image information obtained through decoding to perform segmentation. Ultimately, the FCN model created a structure that eliminates the need for preprocessing through convolutionalization, allows input regardless of image size, preserves image position information, enables pixel-wise segmentation through deconvolution, and uses skip architecture for more refined segmentation. This model achieved a 20% improvement in Mean IU over the CK model in the Pascal VOC 2012 segmentation test.


# FCNs
FCN은 컴퓨터비전 분야에 인공지능 모델이 많지 않던 '15년도에 등장한 모델이다. 

분류모델로는 VGGnet, GoogLeNet 등이 있었고, 객체 검출 모델로는 R-CNN 모델이 있었다. 다만, 컴퓨터비전 과제에서 세그멘테이션 문제에 대한 해결방법이 특별히 없던 시기였다. 전통적인 CNN 모델을 이용하여 세그멘테이션도 가능했지만, 이는 주로 분류 기반의 모델이다 보니 이미지 전체에 대한 글로벌 피쳐를 찾아 분석하는 방식이었고, 객체 검출 모델은 전용 패턴 인식용 필터를 사용해야 해서 전반적으로 활용성이 높지 않았다. 이에 이 글에서는 픽셀마다 예측이 가능한 모델인 FCN에 대해 설명하고자 한다. 참고로 기존의 세그멘테이션 방식으로는 patchwise와 pixelwise 방식이 사용되었는데, 이 방식들은 계산량이 많고 수퍼픽셀과 같은 문제로 많은 전후처리를 동반하였다. 

FCN의 특징을 세가지 정의하자면 아래와 같다.

첫째, FCN 모델의 의의는 전처리가 불필요한 이미지 세그멘테이션 모델이라는 것이다. 기존 CNN 모델은 컨볼루셔널 레이어와 풀링 레이어를 거친 후 마지막에 풀리 커넥티드 레이어가 있는데, FCN에는 풀리 커넥티드 레이어가 없다. 일반적인 CNN 모델은 컨볼루셔널 레이어와 풀링 레이어를 통해 이미지의 로컬 피쳐를 뽑고, 이를 추상화 시키는 과정을 가진다. 이를 출력층에서 풀리 커넥티드 레이어로 구성해서 아웃풋에 해당하는 class를 찾는 형태이다. 예를 들어 VGG16 모델의 경우 아웃풋 레이어가 1000개로 구성되어 있어, 1000개의 class를 분류할 수 있는 구조이다. 다만, 이 구조에서 생기는 문제로는 풀리 커넥티드 레이어의 가중치 개수가 고정되어 있기 때문에, 바로 앞 레이어의 피쳐맵의 크기도 고정되고, 연쇄적으로 인풋 이미지의 크기가 고정되게 된다. FCN에서는 이 풀리커넥티드 레이어를 컨볼루셔널 레이어로 변경하였다. 이를 컨볼루셔널라이제이션이라고 한다. 이 결과 아웃풋 레이어의 구조적인 제한이 없어져 입력 크기의 제한이 사라지게 되어 이미지 전처리가 불필요해진다. 즉, 인풋 크기에 따라 유동적인 아웃풋이 나오는 구조로 변경되었다. 그리고 FCN은 세그멘테이션 분야의 기술로, CNN의 분류기술과 객체의 로컬라이제이션, 즉 위치의 정보가 필요하다. 기존 CNN 모델은 로컬 피쳐를 뽑고, 이를 추상화 시키기에 이미지 전체의 의미만 남고 위치 정보는 잃어버리게 된다. 이는 앞서 본 풀리 커넥티드 레이어에서 전체 픽셀을 1자로 잇는 과정 때문에 생기는 문제로, FCN은 풀리커넥티드레이어를 없애고 컨볼루셔널라이제이션을 수행하여 각 픽셀의 정보를 유지하고 이를 히트맵 형식으로 표현할 수 있다. 컨볼루셔널라이제이션 수행방식은 기존 풀리커넷티드 레이어의 노드수에 따라 가중치 수를 유지할 수 있는 1*1 필터 여러개를 적용하는 식이다. VGG16의 경우 기존 풀리커넥티드 레이어의 노드수가 4096개이므로, 1*1필터 4096개를 적용하는 방식으로 수행된다. 정리하자면 FCN의 의의는 컨볼루셔널라이제이션을 통해 전처리가 불필요한 이미지 분할을 수행한다는데 있다. 

둘째, FCN에서는 이미지 세그멘테이션을 위한 특별한 기법이 있다. 첫째 내용에서 살펴본 바와 같이, 컨볼루셔널라이제이션을 통해 입력 이미지 대비 압축된 히트맵을 추출하였으나, 최종 세그멘테이션 목적지인 픽셀단위 예측을 위해서 특별한 기법이 필요하다. 그 방식이 바로 압축된 이미지를 다시 크게 키우는 역필터링 기법이다. FCN에서는 쉬프트 앤 스티취, 이중선형보간법, 디컨볼루션 중 디컨볼루션 기법을 이용한다. 컨볼루션의 역 연산을 이용하여 압축된 피쳐맵에 필터의 역을 연산하는 방식이다. 역필터링 기법으로 디컨볼루션을 이용하여 이미지 크기를 복원하고, 픽셀단위 예측을 수행할 수 있도록 한다. 

셋째, 앞서 살펴본 FCN의 구조는 인코더-디코더 구조라고 볼 수 있다. 인코더 구조에서는 기존의 CNN 방식들과 동일하게 이미지의 분류를 위한 압축/추상화 과정을 진행하며, 피쳐맵은 5번의 컨볼루셔널-풀링 레이어를 거치며 1/32배로 압축되게 되고, 인코더는 CNN의 목표에 따라 딥레이어의 의미적인 정보, 즉 전체 이미지의 글로벌한 정보를 얻을 수 있는 구조이다. 이후 디코더는 인코딩으로 압축된 피쳐맵을 고화질화 한다. 가장 기본적인 FCN-32방식은 디컨볼루션을 통해 32배 확대하는 방식이나, 화질이 떨어지게 된다. 이를 개선하기 위해 FCN-16이라는 모델이 등장하였다. 방식은 2배 확대 후 풀링레이어 4번의 피쳐맵을 합쳐준 후 다시 16배 확대하는 방식으로, 기존 피쳐맵 일부를 원본 그대로 가져와 합쳐주어 화질을 개선한다. 동일한 방식을 재적용한 FCN-8 모델은 2배 확대 후 풀링레이어 4번의 피쳐맵을 합쳐주고, 2배 확대 후 풀링레이어 3번의 피쳐맵을 합쳐준 후에 8배 확대하는 방식이다. 이렇게 디코더는 인코딩 되기 전 스왈로우레이어의 세밀한 이미지 정보를 얻을 수 있게 되었고, 실제로 관련 논문의 성능 지표를 봤을 때도 실제 이미지와 예측 이미지간의 픽셀 정확도 등이 높아지는 결과를 볼 수 있다. 

정리하자면, FCN은 인코딩 과정에서 손실될 뻔한 정보를, 이전 피쳐맵의 정보를 그대로 가져와 합치는 스킵 아키텍쳐를 통해 복원하는 구조이며, 인코더를 통해 얻은 전체 이미지 정보와 디코더를 통해 얻은 세밀한 이미지 정보를 혼합하여 세그멘테이션하는 모델이다. 최종적으로 정리하자면, FCN 모델은 컨볼루셔널라이제이션을 통해 풀리커넥티드 레이어를 없애고, 이미지 크기 상관 없이 입력 가능하며, 이미지의 위치정보도 잃어버리지 않는 구조를 만들었고, 디컨볼루셔널 기법을 통해 압축된 이미지를 업샘플링하여 픽셀단위 분할이 가능하도록 하였으며, 스킵아키텍처를 적용하여 보다 정교한 분할이 가능하도록 한 모델이다. 이 모델은 파스칼 VOC 2012 세그멘테이션 테스트에서 기존 모델인 CK보다 20% 향상된 Mean IU로 SOTA를 달성하였다. 
